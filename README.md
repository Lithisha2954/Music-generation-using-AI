# Music-generation-using-AI
This project uses Recurrent Neural Networks (RNNs), specifically LSTM, to generate new music by learning patterns from MIDI files. It converts music into sequences, trains the model to predict notes, and generates melodies. Implemented in Python with TensorFlow and PrettyMIDI.          
This project explores AI-based music generation using Recurrent Neural Networks (RNNs), specifically LSTM layers, to compose new musical sequences by learning from existing MIDI data. The system first extracts and preprocesses note information (pitch, duration, step) from MIDI files using the PrettyMIDI library. These sequences are then used to train a deep learning model that predicts the next note based on prior context, enabling it to generate coherent melodies. The model is built using TensorFlow and trained on note sequences to learn temporal patterns in musical structure. After training, it generates music by sampling predicted notes, which are then converted back into MIDI format for playback. Additional tools like pyfluidsynth and IPython.display are used to render and listen to the generated compositions. This project demonstrates how deep learning can be applied creatively to generate original instrumental music and highlights the potential of AI in the field of algorithmic music composition.
